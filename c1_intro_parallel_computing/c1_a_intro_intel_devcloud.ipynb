{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Jupyter Notebooks on the Intel DevCloud for oneAPI Projects! \n",
    "This document covers the basics of the JupyterLab access to the Intel DevCloud for oneAPI Projects. It is not a tutorial on the JupyterLab itself. Rather, we will run through a few examples of how to use the computational resources available on the DevCloud *beyond* the notebook.\n",
    "\n",
    "The diagram below illustrates the high-level organization of the DevCloud. This tutorial explains how to navigate this organization. \n",
    "\n",
    "<img src=\"https://devcloud.intel.com/oneapi/static/images/svg/cluster-jn-organization.svg\" style=\"max-width:600px;\" />\n",
    "\n",
    "\n",
    "## Service Terms\n",
    "\n",
    "By using the Intel DevCloud for oneAPI Projects, you are agreeing to the following terms linked in the footer of the Intel DevCloud website: <br />\n",
    "<a href=\"https://devcloud.intel.com/oneapi/\">https://devcloud.intel.com/oneapi/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Notebook Basics](#sec-basics)\n",
    "2. [Compute Power and Limits](#sec-limits)\n",
    "3. [Job Queue](#sec-queue)\n",
    "4. [Final Words](#sec-final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-basics\"></a>\n",
    "## 1. Notebook Basics\n",
    "\n",
    "You can find detailed documentation on using the JupyterLab software at <a href=\"https://jupyter.org/\">jupyter.org</a>. For our tutorial, you just need to know that \n",
    "- When you see cells like below (the line that begins with `!echo \"Running...\"`), this is code that you can run. \n",
    "- If you mouse-click on the cell, you will be able to edit the code. \n",
    "- While you are in the cell, press Ctrl+Enter, and the code in the cell will run.\n",
    "- In the top-right corner of the page, the indicator <i class=\"kernel_idle_icon\"></i> will change to <i class=\"kernel_busy_icon\"></i>. This means that the kernel is busy. \n",
    "- If the code begins with \"!\", it will run in the Bash shell. Otherwise, it is treated as Python code.\n",
    "\n",
    "Go ahead, click the cell below and then press Ctrl+Enter. You should see \"Running...\" and a few seconds later \"...done\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "...done!\n"
     ]
    }
   ],
   "source": [
    "!echo \"Running...\"; sleep 3; echo \"...done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sec-limits\"></a>\n",
    "## 2. Compute Power and Limits\n",
    "For the most part, the Notebook session on the DevCloud should be familiar to JupyterLab users. However, there are few limitations that you should be aware of.\n",
    "\n",
    "* ### Session Time\n",
    " Your JupyterLab session has a time limit. \n",
    " If your session runs out of time, you can start a new one by refreshing the page or going to <a href=\"https://jupyter.oneapi.devcloud.intel.com\">jupyter.oneapi.devcloud.intel.com</a> again. However, keep in mind that\n",
    " * The contents of the Notebook will not be automatically saved when the session time runs out. Save your work!\n",
    " * All running processes (the notebook itself, the kernels running in it, terminals) are terminated. If you want to run calculations that survive outside the notebook, use the <a href=\"#sec-queue\">job queue</a> as described below.\n",
    "\n",
    "* ### Number of Cores\n",
    " Your Notebook is running on a powerful computing server, but other people may be running Notebooks on the same server. They cannot access your files, but you do share the pool of the CPU cores. For heavy workloads (e.g., neural network training), you can get access to more computing power by submitting scripts to the <a href=\"#sec-queue\">job queue</a> as discussed below.\n",
    " \n",
    "* ### Amount of Memory\n",
    " Your Notebook is also sharing the computing server's operating memory with other tenants. If you need more memory for calculations, use the <a href=\"#sec-queue\">job queue</a>.\n",
    " \n",
    "Run the code in the cell below to query the limits of your JupyterLab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* How many seconds are left in my JupyterLab session?\n",
      "    Walltime.Remaining = 12434\n",
      "* How many logical CPUs do I have for the Notebook?\n",
      "pid 2747249's current affinity list: 6-11,18-23\n",
      "* How much RAM can I use in the Notebook?\n",
      "    resources_used.vmem = 6815176kb\n",
      "    Resource_List.vmem = 94gb\n"
     ]
    }
   ],
   "source": [
    "!echo \"* How many seconds are left in my JupyterLab session?\"\n",
    "!qstat -f $PBS_JOBID | grep Walltime.Remaining\n",
    "\n",
    "!echo \"* How many logical CPUs do I have for the Notebook?\"\n",
    "!taskset -c -p $$\n",
    "\n",
    "!echo \"* How much RAM can I use in the Notebook?\"\n",
    "!/usr/local/bin/qstat -f $PBS_JOBID | grep vmem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sec-queue\"></a>\n",
    "## 3. Job Queue\n",
    "The job queue is the only method for accessing the full capacity of the computing resources available on the DevCloud. This section explains how you can interact with the queue from the JupyterLab environment. You can also submit to the queue from a terminal session. A more detailed guide on queue usage is available on the <a href=\"https://devcloud.intel.com/oneapi/learn/job-submission/\">Intel DevCloud website</a>.\n",
    "\n",
    "\n",
    "### Creating a Job Script\n",
    "To submit a job to the queue, create a Bash script containing the commands that you want to run. \n",
    "You can do this from the Notebook using the `%%writefile` magic. The following example creates a job script called `hello-world-example`. The line `cd $PBS_O_WORKDIR` changes the working directory to the directory where the script is located. Everything else runs in the Bash shell on the designated compute server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello-world-example\n"
     ]
    }
   ],
   "source": [
    "%%writefile hello-world-example\n",
    "cd $PBS_O_WORKDIR\n",
    "echo \"* Hello world from compute server `hostname`!\"\n",
    "echo \"* The current directory is ${PWD}.\"\n",
    "echo \"* Compute server's CPU model and number of logical CPUs:\"\n",
    "lscpu | grep 'Model name\\\\|^CPU(s)'\n",
    "echo \"* Python available to us:\"\n",
    "which python\n",
    "python --version\n",
    "echo \"* The job can create files, and they will be visible back in the Notebook.\" > newfile.txt\n",
    "sleep 10\n",
    "echo \"*Bye\"\n",
    "# Remember to have an empty line at the end of the file; otherwise the last command will not run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see the file `hello-world-example` when you go to the tree menu, or if you run the `%ls` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34massets\u001b[0m/                            c1_c_python_benchmarking.ipynb\n",
      "c1_a_intro_intel_devcloud.ipynb    c1_README.md\n",
      "c1_b_python_multiprocessing.ipynb  hello-world-example\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only Bash job scripts are supported. If you need to run a Python application, add the corresponding Python launch line to the job script. For example:\n",
    "\n",
    "    %%writefile my_job_script\n",
    "    echo \"Running myapplication.py\"\n",
    "    python myapplication.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting a Job to the Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can submit this script as a job using the `qsub` command. Go ahead and execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1901400.v-qsvr-1.aidevcloud\n"
     ]
    }
   ],
   "source": [
    "!qsub hello-world-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have submitted a job to the queue. You should see an output line that looks like \"[numbers].cXXX\". \n",
    "The number you see in the front is the Job ID. We will be using this number to retrieve the output of the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Queue Status\n",
    "Once the job has been placed in the queue, you can find the current status of the job by running the followng command in a cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID                    Name             User            Time Use S Queue\n",
      "------------------------- ---------------- --------------- -------- - -----\n",
      "1901390.v-qsvr-1           ...ub-singleuser u134923         00:00:46 R jupyterhub     \n",
      "1901400.v-qsvr-1           ...world-example u134923                0 R batch          \n"
     ]
    }
   ],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran `qstat` soon enough, you will see a job with the name `...world-example`. In the column `S` you will see a letter indicating its status: \"Q\" is for \"queued\", \"R\" is for \"running\", and \"E\" is either an error, or a transition to a normal job completion. If you still see an entry for `...world-example`, keep re-running the above cell a few times until the \"hello world\" job completes and disappears from the list. If you don't see this entry, proceed to the next section to view the results of our job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the result\n",
    "Once the job is completed, the resulting output and error streams (stdout and stderr) are placed in two seperate text files. These output files have the following naming convention: \n",
    "\n",
    "* stdout: [Job Name].o[Job ID].    Example: `hello-world-example.o12345`\n",
    "* stderr: [Job Name].e[Job ID].    Example: `hello-world-example.e12345`\n",
    "\n",
    "[Job Name] is either the script name, or a custom name — for example, the name specified by the `-N` parameter of `qsub`. \n",
    "\n",
    "[Job ID] is the number you got from the output of the `qsub` command. \n",
    "\n",
    "Let's find the output file produced by the `hello-world-example` job by running the `%ls` magic again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello-world-example  hello-world-example.e1901400  hello-world-example.o1901400\n"
     ]
    }
   ],
   "source": [
    "%ls hello-world-example*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view this file, you can go to File -> Open... click on the `hello-world-example.o*` file. Alternatively, you can view the contents of the file inside the JupyterLab using the `%cat` magic command. Run the cell below to view the result of the \"hello world\" job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################################################\n",
      "#      Date:           Sun 08 May 2022 05:48:41 PM PDT\n",
      "#    Job ID:           1901400.v-qsvr-1.aidevcloud\n",
      "#      User:           u134923\n",
      "# Resources:           neednodes=1:batch:ppn=2,nodes=1:batch:ppn=2,walltime=06:00:00\n",
      "########################################################################\n",
      "\n",
      "* Hello world from compute server s001-n009!\n",
      "* The current directory is /home/u134923/csula-ee3445-final-project/c1_intro_parallel_computing.\n",
      "* Compute server's CPU model and number of logical CPUs:\n",
      "CPU(s):                          24\n",
      "Model name:                      Intel(R) Xeon(R) Gold 6128 CPU @ 3.40GHz\n",
      "* Python available to us:\n",
      "/glob/development-tools/versions/oneapi/2022.1.2/oneapi/intelpython/latest/bin/python\n",
      "Python 3.9.7 :: Intel Corporation\n",
      " *Bye\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 1901400.v-qsvr-1.aidevcloud\n",
      "# Date: Sun 08 May 2022 05:48:56 PM PDT\n",
      "########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cat hello-world-example.o*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error stream goes to the .e* files. For our job, it contains the Python version (not because we had an error, but because Python chooses to write the version to the error stream):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat hello-world-example.e*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, any files created by the job will be visible after its completion. Useful for data processing tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* The job can create files, and they will be visible back in the Notebook.\n"
     ]
    }
   ],
   "source": [
    "%cat newfile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colfax Magic for Job Submission\n",
    "\n",
    "We have created a custom cell magic command `%%qsub` to simplify job submission from Notebooks. \n",
    "The magic is defined as a part of the `cfxmagic` module. You can use it after you have imported the module. Run the cells below to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing PythonDemo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile PythonDemo.py\n",
    "# Creating an example Python application. \n",
    "# You can do it with the %%writefile magic like we are doing here,\n",
    "# or you can go to the File menu, choose Open, and from there\n",
    "# either upload your code or create a .py file and compose it in the Notebook\n",
    "print (\"Hello world from Python!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfxmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1901401.v-qsvr-1.aidevcloud\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%qsub\n",
    "cd $PBS_O_WORKDIR\n",
    "python PythonDemo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will submit the contents of the cell as a job named STDIN, without writing the script into a separate file. \n",
    "\n",
    "Wait a few moments and then view the output of the job by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'STDIN.*': No such file or directory\n",
      "cat: 'STDIN.o*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%ls STDIN.*\n",
    "%cat STDIN.o*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Parameters\n",
    "Both the `!qsub <file>` command and the `%%qsub` magic can take a variety of parameters that you can set. For example, the following command requests a wall clock time limit of 24 hours and passes a command line argument equal to \"13.2\" to the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1901402.v-qsvr-1.aidevcloud\n"
     ]
    }
   ],
   "source": [
    "!qsub hello-world-example -l walltime=24:00:00 -F \"13.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "# Create queues and set their attributes.\n",
      "#\n",
      "#\n",
      "# Create and define queue batch\n",
      "#\n",
      "create queue batch\n",
      "set queue batch queue_type = Execution\n",
      "set queue batch max_queuable = 5000\n",
      "set queue batch max_user_queuable = 20\n",
      "set queue batch max_running = 90\n",
      "set queue batch resources_max.nodes = 2\n",
      "set queue batch resources_max.walltime = 24:00:00\n",
      "set queue batch resources_default.nodes = 1:batch:ppn=2\n",
      "set queue batch resources_default.walltime = 06:00:00\n",
      "set queue batch resources_available.nodect = 60\n",
      "set queue batch max_user_run = 5\n",
      "set queue batch enabled = True\n",
      "set queue batch started = True\n"
     ]
    }
   ],
   "source": [
    "!qmgr -c 'p q batch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting Multiple Jobs\n",
    "\n",
    "You can submit a number of jobs at once. If enough compute servers are available, all jobs will run simultaneously. Otherwise, they will stay in the queue waiting for their turn to run. \n",
    "\n",
    "When you submit a lot of jobs, be aware that the queue has a fair share-based scheduling policy, so the more you run, the more often will your jobs yield to other users' calculations.\n",
    "\n",
    "You can learn about the pool of compute servers available for your jobs by running the commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* How many compute servers are available?\n",
      "282\n",
      "* How many of them are free?\n",
      "190\n",
      "* What are the time limits for queued jobs?\n",
      "set queue batch resources_max.walltime = 24:00:00\n",
      "set queue batch resources_default.walltime = 06:00:00\n",
      "* What is the configuration of the available compute servers?\n",
      "     properties = core,cfl,i9-10920x,ram32gb,net1gbe,gpu,iris_xe_max,gpu\n",
      "     properties = xeon,cfl,e-2176g,ram64gb,net1gbe,gpu,gen9\n",
      "     properties = xeon,clx,ram192gb,net1gbe,batch,extended,fpga,stratix10,fpga_runtime\n",
      "     properties = xeon,icx,gold6348,ramgb,netgbe,jupyter,batch\n",
      "     properties = xeon,icx,plat8358,ram256gb,net1gbe,batch\n",
      "     properties = xeon,icx,plat8380,ram2tb,net1gbe,batch\n",
      "     properties = xeon,skl,gold6128,ram192gb,net1gbe,fpga_runtime,fpga,arria10\n",
      "     properties = xeon,skl,gold6128,ram192gb,net1gbe,jupyter,batch\n",
      "     properties = xeon,skl,gold6128,ram192gb,net1gbe,jupyter,batch,fpga_compile\n",
      "     properties = xeon,skl,ram384gb,net1gbe,renderkit\n"
     ]
    }
   ],
   "source": [
    "!echo \"* How many compute servers are available?\"\n",
    "!pbsnodes | grep \"^s\" | wc -l\n",
    "\n",
    "!echo \"* How many of them are free?\"\n",
    "!pbsnodes | grep \"state = free\" | wc -l\n",
    "\n",
    "!echo \"* What are the time limits for queued jobs?\"\n",
    "!qmgr -c 'p q batch' | grep walltime\n",
    "\n",
    "!echo \"* What is the configuration of the available compute servers?\"\n",
    "!pbsnodes | grep properties | sort | uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Running the JupyterLab Code as a Job\n",
    "JupyterLab sessions are designed for interactive computing, which is the opposite of what the job queue is designed for. However, if you structured your Jupyter Notebook code as non-interactive Python application, you can submit your code to the queue. \n",
    "\n",
    "For example, suppose that your Notebook \n",
    "1. Imports some Python modules, \n",
    "2. Loads a dataset, \n",
    "3. Sets up a neural network\n",
    "4. Trains it, and \n",
    "5. Writes the resultant model weights into a file. \n",
    "This is the kind of workload that can benefit from access to a powerful compute server and does not require interactivity. Therefore, you can submit it to the job queue. \n",
    "\n",
    "You can dump the code of all cells in a Notebook into a Python script using the `jupyter` command shown below. Suppose that you have a Notebook saved in the file `mynotebook.ipynb`. The following cell converts the Notebook into a Python script `mynotebook.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'mynotebook.ipynb' matched no files\n",
      "This application is used to convert notebook files (*.ipynb)\n",
      "        to various other formats.\n",
      "\n",
      "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "=======\n",
      "The options below are convenience aliases to configurable class-options,\n",
      "as listed in the \"Equivalent to\" description-line of the aliases.\n",
      "To see all configurable class-options for some <cmd>, use:\n",
      "    <cmd> --help-all\n",
      "\n",
      "--debug\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "    Equivalent to: [--Application.log_level=10]\n",
      "--show-config\n",
      "    Show the application's configuration (human-readable format)\n",
      "    Equivalent to: [--Application.show_config=True]\n",
      "--show-config-json\n",
      "    Show the application's configuration (json format)\n",
      "    Equivalent to: [--Application.show_config_json=True]\n",
      "--generate-config\n",
      "    generate default config file\n",
      "    Equivalent to: [--JupyterApp.generate_config=True]\n",
      "-y\n",
      "    Answer yes to any questions instead of prompting.\n",
      "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
      "--execute\n",
      "    Execute the notebook prior to export.\n",
      "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
      "--allow-errors\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
      "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
      "--stdin\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
      "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
      "--stdout\n",
      "    Write notebook output to stdout instead of files.\n",
      "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
      "--inplace\n",
      "    Run nbconvert in place, overwriting the existing notebook (only \n",
      "            relevant when converting to notebook format)\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
      "--clear-output\n",
      "    Clear output of current file and save in place, \n",
      "            overwriting the existing notebook.\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
      "--no-prompt\n",
      "    Exclude input and output prompts from converted document.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
      "--no-input\n",
      "    Exclude input cells and output prompts from converted document. \n",
      "            This mode is ideal for generating code-free reports.\n",
      "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
      "--allow-chromium-download\n",
      "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
      "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
      "--disable-chromium-sandbox\n",
      "    Disable chromium security sandbox when converting to PDF..\n",
      "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
      "--show-input\n",
      "    Shows code input. This is flag is only useful for dejavu users.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
      "--log-level=<Enum>\n",
      "    Set the log level by value or name.\n",
      "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
      "    Default: 30\n",
      "    Equivalent to: [--Application.log_level]\n",
      "--config=<Unicode>\n",
      "    Full path of a config file.\n",
      "    Default: ''\n",
      "    Equivalent to: [--JupyterApp.config_file]\n",
      "--to=<Unicode>\n",
      "    The export format to be used, either one of the built-in formats\n",
      "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\n",
      "            or a dotted object name that represents the import path for an\n",
      "            ``Exporter`` class\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.export_format]\n",
      "--template=<Unicode>\n",
      "    Name of the template to use\n",
      "    Default: ''\n",
      "    Equivalent to: [--TemplateExporter.template_name]\n",
      "--template-file=<Unicode>\n",
      "    Name of the template file to use\n",
      "    Default: None\n",
      "    Equivalent to: [--TemplateExporter.template_file]\n",
      "--writer=<DottedObjectName>\n",
      "    Writer class used to write the \n",
      "                                        results of the conversion\n",
      "    Default: 'FilesWriter'\n",
      "    Equivalent to: [--NbConvertApp.writer_class]\n",
      "--post=<DottedOrNone>\n",
      "    PostProcessor class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
      "--output=<Unicode>\n",
      "    overwrite base name use for output files.\n",
      "                can only be used when converting one notebook at a time.\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.output_base]\n",
      "--output-dir=<Unicode>\n",
      "    Directory to write output(s) to. Defaults\n",
      "                                  to output to the directory of each notebook. To recover\n",
      "                                  previous default behaviour (outputting to the current \n",
      "                                  working directory) use . as the flag value.\n",
      "    Default: ''\n",
      "    Equivalent to: [--FilesWriter.build_directory]\n",
      "--reveal-prefix=<Unicode>\n",
      "    The URL prefix for reveal.js (version 3.x).\n",
      "            This defaults to the reveal CDN, but can be any url pointing to a copy \n",
      "            of reveal.js. \n",
      "            For speaker notes to work, this must be a relative path to a local \n",
      "            copy of reveal.js: e.g., \"reveal.js\".\n",
      "            If a relative path is given, it must be a subdirectory of the\n",
      "            current directory (from which the server is run).\n",
      "            See the usage documentation\n",
      "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
      "            for more details.\n",
      "    Default: ''\n",
      "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
      "--nbformat=<Enum>\n",
      "    The nbformat version to write.\n",
      "            Use this to downgrade notebooks.\n",
      "    Choices: any of [1, 2, 3, 4]\n",
      "    Default: 4\n",
      "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to html\n",
      "\n",
      "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf'].\n",
      "\n",
      "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
      "\n",
      "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and \n",
      "            'classic'. You can specify the flavor of the format used.\n",
      "\n",
      "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
      "\n",
      "            You can also pipe the output to stdout, rather than a file\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
      "\n",
      "            PDF is generated via latex\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
      "\n",
      "            You can get (and serve) a Reveal.js-powered slideshow\n",
      "\n",
      "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
      "\n",
      "            Multiple notebooks can be given at the command line in a couple of \n",
      "            different ways:\n",
      "\n",
      "            > jupyter nbconvert notebook*.ipynb\n",
      "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
      "\n",
      "            or you can specify the notebooks list in a config file, containing::\n",
      "\n",
      "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "\n",
      "            > jupyter nbconvert --config mycfg.py\n",
      "\n",
      "To see all available configurables, use `--help-all`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do not try to run this unless you already have a file called mynotebook.ipynb\n",
    "# This is just an illustration.\n",
    "!jupyter nbconvert --to script \"mynotebook.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: mynotebook.py: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# This will view the resultant Python code mynotebook.py\n",
    "!cat \"mynotebook.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above commands should have created a Python script named `mynotebook.py`. You can submit this script to the queue as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3277707077.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [22]\u001b[0;36m\u001b[0m\n\u001b[0;31m    cd $PBS_O_WORKDIR\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Do not submit; this is an illustration.\n",
    "%%qsub\n",
    "cd $PBS_O_WORKDIR\n",
    "python mynotebook.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sec-final\"></a>\n",
    "## 4. Final Notes\n",
    "This document covered some of the basics of using the JupyterLab environment on the DevCloud. \n",
    "\n",
    "JupyterLab is not the only way to access the DevCloud. You can also log in with an SSH client or a file transfer application based on the SSH protocol (e.g., WinSCP or FileZilla). This may be a more convenient access mode for advanced users who already have the code base developed, and who want to execute their code on powerful compute resources.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
